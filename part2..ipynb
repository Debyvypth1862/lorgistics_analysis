{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8161714",
   "metadata": {},
   "source": [
    "# Estimated Delivery Date (EDD) Accuracy Analysis\n",
    "\n",
    "This notebook analyzes the accuracy of Estimated Delivery Dates (EDD) across different carriers using the provided parcel and log data.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Determine which carrier has the highest EDD accuracy\n",
    "2. Identify patterns in the provided estimated delivery dates\n",
    "3. Visualize and quantify EDD performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b01f8d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, let's import the necessary libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc4e0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting styles\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9960ea1",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "\n",
    "Let's load the parquet files and examine their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "76b05a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcel Table Shape: (50083, 9)\n",
      "Log Table Shape: (94771, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the parcel and log tables\n",
    "parcel_df = pd.read_parquet('parcel_table.pqt')\n",
    "log_df = pd.read_parquet('log_table.pqt')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Parcel Table Shape:\", parcel_df.shape)\n",
    "print(\"Log Table Shape:\", log_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b7c4c332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>carrier_name</th>\n",
       "      <th>picked_up_date</th>\n",
       "      <th>out_for_delivery_date</th>\n",
       "      <th>first_attempt_date</th>\n",
       "      <th>final_delivery_date</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>destination_country</th>\n",
       "      <th>is_delivered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2981186961</td>\n",
       "      <td>Initech</td>\n",
       "      <td>2024-06-20 7:00:11</td>\n",
       "      <td>2024-06-20 20:57:51</td>\n",
       "      <td>2024-06-20 22:18:27</td>\n",
       "      <td>2024-06-20 22:18:27</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2948380100</td>\n",
       "      <td>Initech</td>\n",
       "      <td>2024-06-08 6:00:06</td>\n",
       "      <td>2024-06-18 0:12:26</td>\n",
       "      <td>2024-06-18 3:33:55</td>\n",
       "      <td>2024-06-18 3:33:55</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2948508927</td>\n",
       "      <td>Initech</td>\n",
       "      <td>2024-06-21 1:45:00</td>\n",
       "      <td>2024-06-21 21:53:58</td>\n",
       "      <td>2024-06-21 23:42:15</td>\n",
       "      <td>2024-06-21 23:42:15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2941258771</td>\n",
       "      <td>Initech</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-06-12 0:06:19</td>\n",
       "      <td>2024-06-12 1:18:39</td>\n",
       "      <td>2024-06-12 1:18:39</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2980427311</td>\n",
       "      <td>Massive</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-06-22 23:09:38</td>\n",
       "      <td>2024-06-23 2:43:15</td>\n",
       "      <td>2024-06-23 2:43:15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parcel_id carrier_name      picked_up_date out_for_delivery_date  \\\n",
       "0  2981186961      Initech  2024-06-20 7:00:11   2024-06-20 20:57:51   \n",
       "1  2948380100      Initech  2024-06-08 6:00:06    2024-06-18 0:12:26   \n",
       "2  2948508927      Initech  2024-06-21 1:45:00   2024-06-21 21:53:58   \n",
       "3  2941258771      Initech                None    2024-06-12 0:06:19   \n",
       "4  2980427311      Massive                None   2024-06-22 23:09:38   \n",
       "\n",
       "    first_attempt_date  final_delivery_date origin_country  \\\n",
       "0  2024-06-20 22:18:27  2024-06-20 22:18:27      Australia   \n",
       "1   2024-06-18 3:33:55   2024-06-18 3:33:55      Australia   \n",
       "2  2024-06-21 23:42:15  2024-06-21 23:42:15      Australia   \n",
       "3   2024-06-12 1:18:39   2024-06-12 1:18:39      Australia   \n",
       "4   2024-06-23 2:43:15   2024-06-23 2:43:15      Australia   \n",
       "\n",
       "  destination_country  is_delivered  \n",
       "0           Australia          True  \n",
       "1           Australia          True  \n",
       "2           Australia          True  \n",
       "3           Australia          True  \n",
       "4           Australia          True  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the first few rows of the parcel table\n",
    "parcel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6e50af32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>raw_log_description</th>\n",
       "      <th>log_key</th>\n",
       "      <th>log_timestamp</th>\n",
       "      <th>additional_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>935869563</td>\n",
       "      <td>2928654176</td>\n",
       "      <td>Carrier EDD generated</td>\n",
       "      <td>EDD101</td>\n",
       "      <td>2024-06-04 0:08:08</td>\n",
       "      <td>{\"event_type_master_data_id\": \"EDD101\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910688054</td>\n",
       "      <td>2928669922</td>\n",
       "      <td>Carrier EDD generated</td>\n",
       "      <td>EDD101</td>\n",
       "      <td>2024-06-02 12:20:39</td>\n",
       "      <td>{\"event_type_master_data_id\": \"EDD101\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910688054</td>\n",
       "      <td>2928669922</td>\n",
       "      <td>Carrier EDD generated</td>\n",
       "      <td>EDD101</td>\n",
       "      <td>2024-06-02 12:20:39</td>\n",
       "      <td>{\"event_type_master_data_id\": \"EDD101\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910688054</td>\n",
       "      <td>2928669922</td>\n",
       "      <td>Carrier EDD generated</td>\n",
       "      <td>EDD101</td>\n",
       "      <td>2024-06-02 12:20:39</td>\n",
       "      <td>{\"event_type_master_data_id\": \"EDD101\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910688054</td>\n",
       "      <td>2928669922</td>\n",
       "      <td>Carrier EDD generated</td>\n",
       "      <td>EDD101</td>\n",
       "      <td>2024-06-02 12:20:39</td>\n",
       "      <td>{\"event_type_master_data_id\": \"EDD101\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_id   parcel_id    raw_log_description log_key        log_timestamp  \\\n",
       "0  935869563  2928654176  Carrier EDD generated  EDD101   2024-06-04 0:08:08   \n",
       "1  910688054  2928669922  Carrier EDD generated  EDD101  2024-06-02 12:20:39   \n",
       "2  910688054  2928669922  Carrier EDD generated  EDD101  2024-06-02 12:20:39   \n",
       "3  910688054  2928669922  Carrier EDD generated  EDD101  2024-06-02 12:20:39   \n",
       "4  910688054  2928669922  Carrier EDD generated  EDD101  2024-06-02 12:20:39   \n",
       "\n",
       "                         additional_params  \n",
       "0  {\"event_type_master_data_id\": \"EDD101\"}  \n",
       "1  {\"event_type_master_data_id\": \"EDD101\"}  \n",
       "2  {\"event_type_master_data_id\": \"EDD101\"}  \n",
       "3  {\"event_type_master_data_id\": \"EDD101\"}  \n",
       "4  {\"event_type_master_data_id\": \"EDD101\"}  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the first few rows of the log table\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8acaab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parcel_id</th>\n",
       "      <td>50083.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2958565527.88</td>\n",
       "      <td>39731498.72</td>\n",
       "      <td>1372063139.00</td>\n",
       "      <td>2935887455.00</td>\n",
       "      <td>2953583593.00</td>\n",
       "      <td>2983831471.00</td>\n",
       "      <td>3009728867.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrier_name</th>\n",
       "      <td>50063</td>\n",
       "      <td>4</td>\n",
       "      <td>Initech</td>\n",
       "      <td>45978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picked_up_date</th>\n",
       "      <td>21594</td>\n",
       "      <td>3576</td>\n",
       "      <td>2024-06-22 5:15:13</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_for_delivery_date</th>\n",
       "      <td>49277</td>\n",
       "      <td>8489</td>\n",
       "      <td>2024-06-12 19:10:27</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_attempt_date</th>\n",
       "      <td>49616</td>\n",
       "      <td>8612</td>\n",
       "      <td>2024-06-29 1:07:33</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_delivery_date</th>\n",
       "      <td>49381</td>\n",
       "      <td>8593</td>\n",
       "      <td>2024-06-29 1:07:33</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin_country</th>\n",
       "      <td>50060</td>\n",
       "      <td>15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>49445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>destination_country</th>\n",
       "      <td>50055</td>\n",
       "      <td>3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>49769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_delivered</th>\n",
       "      <td>50083</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>49401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique                  top   freq  \\\n",
       "parcel_id             50083.00    NaN                  NaN    NaN   \n",
       "carrier_name             50063      4              Initech  45978   \n",
       "picked_up_date           21594   3576   2024-06-22 5:15:13    182   \n",
       "out_for_delivery_date    49277   8489  2024-06-12 19:10:27    304   \n",
       "first_attempt_date       49616   8612   2024-06-29 1:07:33    304   \n",
       "final_delivery_date      49381   8593   2024-06-29 1:07:33    304   \n",
       "origin_country           50060     15            Australia  49445   \n",
       "destination_country      50055      3            Australia  49769   \n",
       "is_delivered             50083      2                 True  49401   \n",
       "\n",
       "                               mean         std           min           25%  \\\n",
       "parcel_id             2958565527.88 39731498.72 1372063139.00 2935887455.00   \n",
       "carrier_name                    NaN         NaN           NaN           NaN   \n",
       "picked_up_date                  NaN         NaN           NaN           NaN   \n",
       "out_for_delivery_date           NaN         NaN           NaN           NaN   \n",
       "first_attempt_date              NaN         NaN           NaN           NaN   \n",
       "final_delivery_date             NaN         NaN           NaN           NaN   \n",
       "origin_country                  NaN         NaN           NaN           NaN   \n",
       "destination_country             NaN         NaN           NaN           NaN   \n",
       "is_delivered                    NaN         NaN           NaN           NaN   \n",
       "\n",
       "                                50%           75%           max  \n",
       "parcel_id             2953583593.00 2983831471.00 3009728867.00  \n",
       "carrier_name                    NaN           NaN           NaN  \n",
       "picked_up_date                  NaN           NaN           NaN  \n",
       "out_for_delivery_date           NaN           NaN           NaN  \n",
       "first_attempt_date              NaN           NaN           NaN  \n",
       "final_delivery_date             NaN           NaN           NaN  \n",
       "origin_country                  NaN           NaN           NaN  \n",
       "destination_country             NaN           NaN           NaN  \n",
       "is_delivered                    NaN           NaN           NaN  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get descriptive statistics for the parcel table\n",
    "parcel_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ca9f771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_id</th>\n",
       "      <td>94771.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-435480580.19</td>\n",
       "      <td>1624261695.34</td>\n",
       "      <td>-2147483648.00</td>\n",
       "      <td>-2147483648.00</td>\n",
       "      <td>905028318.00</td>\n",
       "      <td>1074168150.00</td>\n",
       "      <td>1430976400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parcel_id</th>\n",
       "      <td>94771.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2958544187.55</td>\n",
       "      <td>23857928.03</td>\n",
       "      <td>2928654176.00</td>\n",
       "      <td>2935819684.00</td>\n",
       "      <td>2953484964.00</td>\n",
       "      <td>2983510855.00</td>\n",
       "      <td>3009728867.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_log_description</th>\n",
       "      <td>94771</td>\n",
       "      <td>2</td>\n",
       "      <td>Carrier EDD generated</td>\n",
       "      <td>50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_key</th>\n",
       "      <td>94771</td>\n",
       "      <td>2</td>\n",
       "      <td>EDD101</td>\n",
       "      <td>50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_timestamp</th>\n",
       "      <td>94771</td>\n",
       "      <td>52324</td>\n",
       "      <td>2024-06-04 3:02:58</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional_params</th>\n",
       "      <td>94771</td>\n",
       "      <td>1197</td>\n",
       "      <td>{\"event_type_master_data_id\": \"EDD101\"}</td>\n",
       "      <td>48902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count unique                                      top  \\\n",
       "log_id              94771.00    NaN                                      NaN   \n",
       "parcel_id           94771.00    NaN                                      NaN   \n",
       "raw_log_description    94771      2                    Carrier EDD generated   \n",
       "log_key                94771      2                                   EDD101   \n",
       "log_timestamp          94771  52324                       2024-06-04 3:02:58   \n",
       "additional_params      94771   1197  {\"event_type_master_data_id\": \"EDD101\"}   \n",
       "\n",
       "                      freq          mean           std            min  \\\n",
       "log_id                 NaN -435480580.19 1624261695.34 -2147483648.00   \n",
       "parcel_id              NaN 2958544187.55   23857928.03  2928654176.00   \n",
       "raw_log_description  50000           NaN           NaN            NaN   \n",
       "log_key              50000           NaN           NaN            NaN   \n",
       "log_timestamp          304           NaN           NaN            NaN   \n",
       "additional_params    48902           NaN           NaN            NaN   \n",
       "\n",
       "                               25%           50%           75%           max  \n",
       "log_id              -2147483648.00  905028318.00 1074168150.00 1430976400.00  \n",
       "parcel_id            2935819684.00 2953484964.00 2983510855.00 3009728867.00  \n",
       "raw_log_description            NaN           NaN           NaN           NaN  \n",
       "log_key                        NaN           NaN           NaN           NaN  \n",
       "log_timestamp                  NaN           NaN           NaN           NaN  \n",
       "additional_params              NaN           NaN           NaN           NaN  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get descriptive statistics for the log table\n",
    "log_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "66aac3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in parcel table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>picked_up_date</th>\n",
       "      <td>28489</td>\n",
       "      <td>56.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_for_delivery_date</th>\n",
       "      <td>806</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_delivery_date</th>\n",
       "      <td>702</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_attempt_date</th>\n",
       "      <td>467</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>destination_country</th>\n",
       "      <td>28</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin_country</th>\n",
       "      <td>23</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrier_name</th>\n",
       "      <td>20</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Count  Percentage\n",
       "picked_up_date         28489       56.88\n",
       "out_for_delivery_date    806        1.61\n",
       "final_delivery_date      702        1.40\n",
       "first_attempt_date       467        0.93\n",
       "destination_country       28        0.06\n",
       "origin_country            23        0.05\n",
       "carrier_name              20        0.04"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the parcel table\n",
    "print(\"Missing values in parcel table:\")\n",
    "missing_parcel = parcel_df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percent_parcel = (missing_parcel / len(parcel_df) * 100).round(2)\n",
    "missing_df_parcel = pd.concat([missing_parcel, missing_percent_parcel], axis=1, keys=['Count', 'Percentage'])\n",
    "missing_df_parcel[missing_df_parcel['Count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "19465da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in log table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Count, Percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the log table\n",
    "print(\"Missing values in log table:\")\n",
    "missing_log = log_df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percent_log = (missing_log / len(log_df) * 100).round(2)\n",
    "missing_df_log = pd.concat([missing_log, missing_percent_log], axis=1, keys=['Count', 'Percentage'])\n",
    "missing_df_log[missing_df_log['Count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fc86d469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcel Table Columns:\n",
      "- parcel_id: int64\n",
      "- carrier_name: object\n",
      "- picked_up_date: object\n",
      "- out_for_delivery_date: object\n",
      "- first_attempt_date: object\n",
      "- final_delivery_date: object\n",
      "- origin_country: object\n",
      "- destination_country: object\n",
      "- is_delivered: bool\n",
      "\n",
      "Log Table Columns:\n",
      "- log_id: int64\n",
      "- parcel_id: int64\n",
      "- raw_log_description: object\n",
      "- log_key: object\n",
      "- log_timestamp: object\n",
      "- additional_params: object\n"
     ]
    }
   ],
   "source": [
    "# Get column information for both datasets\n",
    "print(\"Parcel Table Columns:\")\n",
    "for col in parcel_df.columns:\n",
    "    print(f\"- {col}: {parcel_df[col].dtype}\")\n",
    "\n",
    "print(\"\\nLog Table Columns:\")\n",
    "for col in log_df.columns:\n",
    "    print(f\"- {col}: {log_df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5bd66b",
   "metadata": {},
   "source": [
    "## Comprehensive Data Cleaning and Preparation\n",
    "\n",
    "Let's clean and prepare our data for analysis. This includes:\n",
    "\n",
    "1. Converting timestamp columns to proper datetime format\n",
    "2. Identifying and handling outliers\n",
    "3. Addressing missing values appropriately\n",
    "4. Creating derived features for analysis\n",
    "5. Standardizing categorical fields\n",
    "6. Merging datasets if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0baffe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all timestamp columns to datetime format\n",
    "def convert_timestamps(df, timestamp_pattern=['time', 'date']):\n",
    "    \"\"\"Convert all columns containing time or date in their names to datetime format\"\"\"\n",
    "    original_df = df.copy()\n",
    "    datetime_columns = [col for col in df.columns if any(pattern in col.lower() for pattern in timestamp_pattern)]\n",
    "    \n",
    "    for col in datetime_columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "                print(f\"Converted {col} to datetime\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not convert {col} to datetime: {e}\")\n",
    "                # Restore original column if conversion fails\n",
    "                df[col] = original_df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a939e751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted picked_up_date to datetime\n",
      "Converted out_for_delivery_date to datetime\n",
      "Converted first_attempt_date to datetime\n",
      "Converted final_delivery_date to datetime\n",
      "Converted log_timestamp to datetime\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp columns in both dataframes\n",
    "parcel_df = convert_timestamps(parcel_df)\n",
    "log_df = convert_timestamps(log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85cff955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in parcel_df: 41326\n",
      "Duplicate rows in log_df: 41367\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the data\n",
    "print(f\"Duplicate rows in parcel_df: {parcel_df.duplicated().sum()}\")\n",
    "print(f\"Duplicate rows in log_df: {log_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "77b9adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates if any\n",
    "parcel_df = parcel_df.drop_duplicates()\n",
    "log_df = log_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "92323a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for inconsistent timestamps (e.g., delivery before pickup)\n",
    "def check_timestamp_consistency(df):\n",
    "    \"\"\"Check for logical inconsistencies in timestamps\"\"\"\n",
    "    inconsistencies = []\n",
    "    \n",
    "    # Check if pickup is after final delivery\n",
    "    if 'pick_up' in df.columns and 'final_delivery' in df.columns:\n",
    "        inconsistent_pickup = df[df['pick_up'] > df['final_delivery']]\n",
    "        if len(inconsistent_pickup) > 0:\n",
    "            print(f\"Found {len(inconsistent_pickup)} rows where pickup is after final delivery\")\n",
    "            inconsistencies.append(('pickup_after_delivery', inconsistent_pickup.index))\n",
    "    \n",
    "    # Check if first attempt is before pickup\n",
    "    if 'pick_up' in df.columns and 'first_attempt' in df.columns:\n",
    "        inconsistent_attempt = df[df['first_attempt'] < df['pick_up']]\n",
    "        if len(inconsistent_attempt) > 0:\n",
    "            print(f\"Found {len(inconsistent_attempt)} rows where first attempt is before pickup\")\n",
    "            inconsistencies.append(('attempt_before_pickup', inconsistent_attempt.index))\n",
    "    \n",
    "    # Check if out for delivery is after final delivery\n",
    "    if 'out_for_delivery' in df.columns and 'final_delivery' in df.columns:\n",
    "        inconsistent_out = df[df['out_for_delivery'] > df['final_delivery']]\n",
    "        if len(inconsistent_out) > 0:\n",
    "            print(f\"Found {len(inconsistent_out)} rows where out for delivery is after final delivery\")\n",
    "            inconsistencies.append(('out_after_delivery', inconsistent_out.index))\n",
    "            \n",
    "    return inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e7fafcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for timestamp inconsistencies\n",
    "inconsistencies = check_timestamp_consistency(parcel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6ffa27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to fix inconsistent timestamps or mark rows for exclusion\n",
    "def fix_timestamp_inconsistencies(df, inconsistencies):\n",
    "    \"\"\"Fix or mark inconsistent timestamps\"\"\"\n",
    "    # Create a flag for data quality issues\n",
    "    df['data_quality_issue'] = False\n",
    "    \n",
    "    for issue_type, indices in inconsistencies:\n",
    "        # Mark these rows as having data quality issues\n",
    "        df.loc[indices, 'data_quality_issue'] = True\n",
    "        \n",
    "        # Optionally implement specific fixes based on issue type\n",
    "        if issue_type == 'pickup_after_delivery':\n",
    "            # Example: swap pickup and delivery times for these cases\n",
    "            # df.loc[indices, ['pick_up', 'final_delivery']] = df.loc[indices, ['final_delivery', 'pick_up']].values\n",
    "            pass\n",
    "        \n",
    "        elif issue_type == 'attempt_before_pickup':\n",
    "            # Example: set first_attempt to be at least pickup time\n",
    "            # df.loc[indices, 'first_attempt'] = df.loc[indices, 'pick_up']\n",
    "            pass\n",
    "        \n",
    "        elif issue_type == 'out_after_delivery':\n",
    "            # Example: set out_for_delivery to be before final_delivery\n",
    "            # df.loc[indices, 'out_for_delivery'] = df.loc[indices, 'final_delivery'] - pd.Timedelta(hours=1)\n",
    "            pass\n",
    "    \n",
    "    print(f\"Marked {df['data_quality_issue'].sum()} rows with data quality issues\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "699fa437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marked 0 rows with data quality issues\n"
     ]
    }
   ],
   "source": [
    "# Fix or mark inconsistent timestamps\n",
    "parcel_df = fix_timestamp_inconsistencies(parcel_df, inconsistencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "21b29e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in critical columns\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"Handle missing values in the dataset\"\"\"\n",
    "    # Create a copy to avoid warnings about modifying the original\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # For EDD fields, prefer new values over old when available\n",
    "    if 'new_parcel_expected_time_first_start' in df.columns and 'old_parcel_expected_time_first_start' in df.columns:\n",
    "        df_cleaned['edd_start'] = df_cleaned['new_parcel_expected_time_first_start'].fillna(\n",
    "            df_cleaned['old_parcel_expected_time_first_start'])\n",
    "    \n",
    "    if 'new_parcel_expected_time_latest_end' in df.columns and 'old_parcel_expected_time_latest_end' in df.columns:\n",
    "        df_cleaned['edd_end'] = df_cleaned['new_parcel_expected_time_latest_end'].fillna(\n",
    "            df_cleaned['old_parcel_expected_time_latest_end'])\n",
    "    \n",
    "    # For carrier, we can't reasonably impute missing values\n",
    "    if 'carrier_name' in df.columns:\n",
    "        missing_carrier_count = df_cleaned['carrier_name'].isna().sum()\n",
    "        if missing_carrier_count > 0:\n",
    "            print(f\"Removing {missing_carrier_count} rows with missing carrier information\")\n",
    "            df_cleaned = df_cleaned.dropna(subset=['carrier_name'])\n",
    "    \n",
    "    # For timestamps, we need most of them for meaningful analysis\n",
    "    critical_timestamps = ['pick_up', 'final_delivery', 'edd_start', 'edd_end']\n",
    "    critical_timestamps = [col for col in critical_timestamps if col in df_cleaned.columns]\n",
    "    \n",
    "    if critical_timestamps:\n",
    "        missing_timestamp_count = df_cleaned[critical_timestamps].isna().any(axis=1).sum()\n",
    "        if missing_timestamp_count > 0:\n",
    "            print(f\"Marking {missing_timestamp_count} rows with missing critical timestamps\")\n",
    "            df_cleaned['missing_critical_timestamps'] = df_cleaned[critical_timestamps].isna().any(axis=1)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "04720943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 20 rows with missing carrier information\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "parcel_df_cleaned = handle_missing_values(parcel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a09d4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in transit time\n",
    "def detect_transit_outliers(df):\n",
    "    \"\"\"Detect outliers in transit time\"\"\"\n",
    "    if 'pick_up' in df.columns and 'final_delivery' in df.columns:\n",
    "        # Calculate transit time in days\n",
    "        df['transit_time_days'] = (df['final_delivery'] - df['pick_up']).dt.total_seconds() / (24 * 3600)\n",
    "        \n",
    "        # Check for negative transit times (already captured in inconsistencies)\n",
    "        negative_transit = df[df['transit_time_days'] < 0]\n",
    "        if len(negative_transit) > 0:\n",
    "            print(f\"Found {len(negative_transit)} rows with negative transit time\")\n",
    "        \n",
    "        # Use IQR method to detect outliers\n",
    "        Q1 = df['transit_time_days'].quantile(0.25)\n",
    "        Q3 = df['transit_time_days'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Find outliers\n",
    "        outliers = df[(df['transit_time_days'] < lower_bound) | (df['transit_time_days'] > upper_bound)]\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"Found {len(outliers)} outliers in transit time\")\n",
    "            print(f\"Normal transit time range: {lower_bound:.2f} to {upper_bound:.2f} days\")\n",
    "            \n",
    "            # Mark outliers\n",
    "            df['transit_time_outlier'] = ((df['transit_time_days'] < lower_bound) | \n",
    "                                          (df['transit_time_days'] > upper_bound))\n",
    "            \n",
    "            # Print some statistics about outliers\n",
    "            print(\"\\nTransit time statistics for outliers:\")\n",
    "            print(outliers['transit_time_days'].describe())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6b436d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in transit time\n",
    "parcel_df_cleaned = detect_transit_outliers(parcel_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7a9231a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional derived features for analysis\n",
    "def create_derived_features(df):\n",
    "    \"\"\"Create additional features for analysis\"\"\"\n",
    "    # Create domestic/international flag\n",
    "    if 'origin_country' in df.columns and 'destination_country' in df.columns:\n",
    "        df['is_domestic'] = df['origin_country'] == df['destination_country']\n",
    "        df['trade_lane'] = df['is_domestic'].map({True: 'Domestic', False: 'International'})\n",
    "    \n",
    "    # Create EDD window size in days\n",
    "    if 'edd_start' in df.columns and 'edd_end' in df.columns:\n",
    "        df['edd_window_days'] = (df['edd_end'] - df['edd_start']).dt.total_seconds() / (24 * 3600)\n",
    "        \n",
    "        # Categorize EDD window size\n",
    "        def window_category(days):\n",
    "            if pd.isna(days):\n",
    "                return 'Unknown'\n",
    "            elif days < 1:\n",
    "                return '<1 day'\n",
    "            elif days < 2:\n",
    "                return '1-2 days'\n",
    "            elif days < 3:\n",
    "                return '2-3 days'\n",
    "            elif days < 5:\n",
    "                return '3-5 days'\n",
    "            else:\n",
    "                return '>5 days'\n",
    "                \n",
    "        df['edd_window_category'] = df['edd_window_days'].apply(window_category)\n",
    "    \n",
    "    # Create EDD update flag\n",
    "    if 'new_parcel_expected_time_first_start' in df.columns:\n",
    "        df['edd_updated'] = ~pd.isna(df['new_parcel_expected_time_first_start'])\n",
    "    \n",
    "    # Extract date components for time-based analysis\n",
    "    date_columns = ['pick_up', 'final_delivery', 'edd_start', 'edd_end']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_year'] = df[col].dt.year\n",
    "            df[f'{col}_month'] = df[col].dt.month\n",
    "            df[f'{col}_day'] = df[col].dt.day\n",
    "            df[f'{col}_weekday'] = df[col].dt.dayofweek\n",
    "            df[f'{col}_weekend'] = df[f'{col}_weekday'].isin([5, 6])  # 5=Saturday, 6=Sunday\n",
    "    \n",
    "    # Calculate if delivery was on time (within EDD window)\n",
    "    if 'final_delivery' in df.columns and 'edd_start' in df.columns and 'edd_end' in df.columns:\n",
    "        df['delivery_on_time'] = ((df['final_delivery'] >= df['edd_start']) & \n",
    "                                 (df['final_delivery'] <= df['edd_end']))\n",
    "        \n",
    "        # Calculate how early or late the delivery was (in days)\n",
    "        df['days_early_late'] = (df['final_delivery'] - df['edd_end']).dt.total_seconds() / (24 * 3600)\n",
    "        # Negative values mean early delivery, positive values mean late delivery\n",
    "        \n",
    "        # Categorize delivery timing\n",
    "        def categorize_delivery(days):\n",
    "            if pd.isna(days):\n",
    "                return 'Unknown'\n",
    "            elif days < -3:\n",
    "                return 'Very Early (>3 days)'\n",
    "            elif days < -1:\n",
    "                return 'Early (1-3 days)'\n",
    "            elif days < 0:\n",
    "                return 'Early (<1 day)'\n",
    "            elif days == 0:\n",
    "                return 'On Time'\n",
    "            elif days <= 1:\n",
    "                return 'Late (<1 day)'\n",
    "            elif days <= 3:\n",
    "                return 'Late (1-3 days)'\n",
    "            else:\n",
    "                return 'Very Late (>3 days)'\n",
    "                \n",
    "        df['delivery_category'] = df['days_early_late'].apply(categorize_delivery)\n",
    "        \n",
    "        # Create a delivery performance score (-1 to 1 scale, 0 = perfect delivery)\n",
    "        # Positive means late, negative means early, 0 means exactly on time\n",
    "        df['delivery_performance'] = df['days_early_late'].apply(\n",
    "            lambda x: min(max(x, -1), 1) if not pd.isna(x) else np.nan\n",
    "        )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e2fc971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived features\n",
    "analysis_df = create_derived_features(parcel_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc214126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carriers by shipment volume:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carrier_name</th>\n",
       "      <th>shipment_count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initech</td>\n",
       "      <td>8375</td>\n",
       "      <td>95.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Globex</td>\n",
       "      <td>236</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massive</td>\n",
       "      <td>96</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>30</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  carrier_name  shipment_count  percentage\n",
       "0      Initech            8375       95.86\n",
       "1       Globex             236        2.70\n",
       "2      Massive              96        1.10\n",
       "3      UNKNOWN              30        0.34"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for carriers with very few shipments (potentially not enough data for reliable analysis)\n",
    "carrier_counts = analysis_df['carrier_name'].value_counts().reset_index()\n",
    "carrier_counts.columns = ['carrier_name', 'shipment_count']\n",
    "carrier_counts['percentage'] = carrier_counts['shipment_count'] / len(analysis_df) * 100\n",
    "\n",
    "# Print carriers sorted by shipment count\n",
    "print(\"Carriers by shipment volume:\")\n",
    "carrier_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814f089",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "af4fa619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, filter out carriers with very few shipments\n",
    "min_shipments = 10  # Set this threshold based on your data\n",
    "small_carriers = carrier_counts[carrier_counts['shipment_count'] < min_shipments]['carrier_name'].tolist()\n",
    "\n",
    "if small_carriers:\n",
    "    print(f\"Found {len(small_carriers)} carriers with fewer than {min_shipments} shipments\")\n",
    "    print(\"These carriers will be grouped as 'Other' for analysis:\")\n",
    "    print(small_carriers)\n",
    "    \n",
    "    # Create a copy with grouped carriers\n",
    "    analysis_df_grouped = analysis_df.copy()\n",
    "    analysis_df_grouped.loc[analysis_df_grouped['carrier_name'].isin(small_carriers), 'carrier_name'] = 'OTHER'\n",
    "    \n",
    "    # Check the new distribution\n",
    "    print(\"\\nCarrier distribution after grouping:\")\n",
    "    print(analysis_df_grouped['carrier_name'].value_counts())\n",
    "else:\n",
    "    analysis_df_grouped = analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "299cd065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (8757, 10)\n",
      "Final cleaned shape: (8737, 12)\n",
      "Rows removed: 20\n",
      "Rows with data quality issues: 0 (0.00%)\n",
      "Rows with missing critical timestamps: 0 (0.00%)\n",
      "Rows with transit time outliers: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Final check of the cleaned dataset\n",
    "print(f\"Original shape: {parcel_df.shape}\")\n",
    "print(f\"Final cleaned shape: {analysis_df_grouped.shape}\")\n",
    "print(f\"Rows removed: {parcel_df.shape[0] - analysis_df_grouped.shape[0]}\")\n",
    "\n",
    "# Calculate the percentage of rows with any data quality issues\n",
    "quality_issues = (\n",
    "    analysis_df_grouped['data_quality_issue'].sum() if 'data_quality_issue' in analysis_df_grouped.columns else 0\n",
    ")\n",
    "missing_timestamps = (\n",
    "    analysis_df_grouped['missing_critical_timestamps'].sum() \n",
    "    if 'missing_critical_timestamps' in analysis_df_grouped.columns else 0\n",
    ")\n",
    "transit_outliers = (\n",
    "    analysis_df_grouped['transit_time_outlier'].sum() \n",
    "    if 'transit_time_outlier' in analysis_df_grouped.columns else 0\n",
    ")\n",
    "\n",
    "print(f\"Rows with data quality issues: {quality_issues} ({quality_issues/len(analysis_df_grouped)*100:.2f}%)\")\n",
    "print(f\"Rows with missing critical timestamps: {missing_timestamps} ({missing_timestamps/len(analysis_df_grouped)*100:.2f}%)\")\n",
    "print(f\"Rows with transit time outliers: {transit_outliers} ({transit_outliers/len(analysis_df_grouped)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eb7cd796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>carrier_name</th>\n",
       "      <th>picked_up_date</th>\n",
       "      <th>out_for_delivery_date</th>\n",
       "      <th>first_attempt_date</th>\n",
       "      <th>final_delivery_date</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>destination_country</th>\n",
       "      <th>is_delivered</th>\n",
       "      <th>data_quality_issue</th>\n",
       "      <th>is_domestic</th>\n",
       "      <th>trade_lane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2981186961</td>\n",
       "      <td>Initech</td>\n",
       "      <td>2024-06-20 07:00:11</td>\n",
       "      <td>2024-06-20 20:57:51</td>\n",
       "      <td>2024-06-20 22:18:27</td>\n",
       "      <td>2024-06-20 22:18:27</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2948380100</td>\n",
       "      <td>Initech</td>\n",
       "      <td>2024-06-08 06:00:06</td>\n",
       "      <td>2024-06-18 00:12:26</td>\n",
       "      <td>2024-06-18 03:33:55</td>\n",
       "      <td>2024-06-18 03:33:55</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2948508927</td>\n",
       "      <td>Initech</td>\n",
       "      <td>2024-06-21 01:45:00</td>\n",
       "      <td>2024-06-21 21:53:58</td>\n",
       "      <td>2024-06-21 23:42:15</td>\n",
       "      <td>2024-06-21 23:42:15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2941258771</td>\n",
       "      <td>Initech</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-06-12 00:06:19</td>\n",
       "      <td>2024-06-12 01:18:39</td>\n",
       "      <td>2024-06-12 01:18:39</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2980427311</td>\n",
       "      <td>Massive</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-06-22 23:09:38</td>\n",
       "      <td>2024-06-23 02:43:15</td>\n",
       "      <td>2024-06-23 02:43:15</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parcel_id carrier_name      picked_up_date out_for_delivery_date  \\\n",
       "0  2981186961      Initech 2024-06-20 07:00:11   2024-06-20 20:57:51   \n",
       "1  2948380100      Initech 2024-06-08 06:00:06   2024-06-18 00:12:26   \n",
       "2  2948508927      Initech 2024-06-21 01:45:00   2024-06-21 21:53:58   \n",
       "3  2941258771      Initech                 NaT   2024-06-12 00:06:19   \n",
       "4  2980427311      Massive                 NaT   2024-06-22 23:09:38   \n",
       "\n",
       "   first_attempt_date final_delivery_date origin_country destination_country  \\\n",
       "0 2024-06-20 22:18:27 2024-06-20 22:18:27      Australia           Australia   \n",
       "1 2024-06-18 03:33:55 2024-06-18 03:33:55      Australia           Australia   \n",
       "2 2024-06-21 23:42:15 2024-06-21 23:42:15      Australia           Australia   \n",
       "3 2024-06-12 01:18:39 2024-06-12 01:18:39      Australia           Australia   \n",
       "4 2024-06-23 02:43:15 2024-06-23 02:43:15      Australia           Australia   \n",
       "\n",
       "   is_delivered  data_quality_issue  is_domestic trade_lane  \n",
       "0          True               False         True   Domestic  \n",
       "1          True               False         True   Domestic  \n",
       "2          True               False         True   Domestic  \n",
       "3          True               False         True   Domestic  \n",
       "4          True               False         True   Domestic  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the processed dataset\n",
    "analysis_df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9b66c",
   "metadata": {},
   "source": [
    "## EDD Accuracy Analysis by Carrier\n",
    "\n",
    "Now let's analyze which carrier has the highest EDD accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3c4acf1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: delivery_on_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate on-time delivery percentage by carrier\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m carrier_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43manalysis_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcarrier_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelivery_on_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m carrier_accuracy\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_deliveries\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_time_deliveries\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m carrier_accuracy \u001b[38;5;241m=\u001b[39m carrier_accuracy\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\tran\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m     )\n\u001b[1;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tran\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: delivery_on_time'"
     ]
    }
   ],
   "source": [
    "# Calculate on-time delivery percentage by carrier\n",
    "carrier_accuracy = analysis_df.groupby('carrier_name')['delivery_on_time'].agg(['count', 'sum', 'mean'])\n",
    "carrier_accuracy.columns = ['total_deliveries', 'on_time_deliveries', 'accuracy_rate']\n",
    "carrier_accuracy = carrier_accuracy.sort_values('accuracy_rate', ascending=False).reset_index()\n",
    "\n",
    "# Display carrier accuracy table\n",
    "carrier_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize carrier accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar = sns.barplot(x='carrier_name', y='accuracy_rate', data=carrier_accuracy)\n",
    "plt.title('EDD Accuracy Rate by Carrier')\n",
    "plt.xlabel('carrier_name')\n",
    "plt.ylabel('Accuracy Rate (% of On-Time Deliveries)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, row in enumerate(carrier_accuracy.itertuples()):\n",
    "    bar.text(i, row.accuracy_rate/2, f'{row.accuracy_rate:.1%}', \n",
    "             ha='center', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb09b52",
   "metadata": {},
   "source": [
    "## Delivery Timing Patterns\n",
    "\n",
    "Let's analyze patterns in early and late deliveries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delivery status categories\n",
    "def categorize_delivery(days):\n",
    "    if pd.isna(days):\n",
    "        return 'Unknown'\n",
    "    elif days < -1:\n",
    "        return 'Very Early (>1 day)'\n",
    "    elif days < 0:\n",
    "        return 'Early (<1 day)'\n",
    "    elif days == 0:\n",
    "        return 'On Time'\n",
    "    elif days <= 1:\n",
    "        return 'Late (<1 day)'\n",
    "    else:\n",
    "        return 'Very Late (>1 day)'\n",
    "\n",
    "analysis_df['delivery_category'] = analysis_df['days_early_late'].apply(categorize_delivery)\n",
    "\n",
    "# Analyze distribution of delivery categories by carrier\n",
    "delivery_pattern = pd.crosstab(analysis_df['carrier_name'], analysis_df['delivery_category'], normalize='index')\n",
    "delivery_pattern = delivery_pattern.reset_index()\n",
    "\n",
    "# Display the patterns\n",
    "delivery_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc19c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of delivery patterns by carrier\n",
    "plt.figure(figsize=(14, 8))\n",
    "delivery_pivot = pd.crosstab(analysis_df['carrier_name'], analysis_df['delivery_category'])\n",
    "sns.heatmap(delivery_pivot.div(delivery_pivot.sum(axis=1), axis=0), \n",
    "            annot=True, fmt='.1%', cmap='YlGnBu')\n",
    "plt.title('Delivery Timing Patterns by Carrier')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3687d",
   "metadata": {},
   "source": [
    "## Trade Lane Analysis\n",
    "\n",
    "Let's analyze if there are differences in EDD accuracy based on trade lanes (domestic vs international)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a domestic/international flag\n",
    "analysis_df['is_domestic'] = analysis_df['origin_country'] == analysis_df['destination_country']\n",
    "\n",
    "# Calculate accuracy by carrier and trade lane\n",
    "trade_lane_accuracy = analysis_df.groupby(['carrier_name', 'is_domestic'])['delivery_on_time'].mean().reset_index()\n",
    "trade_lane_accuracy = trade_lane_accuracy.pivot(index='carrier_name', columns='is_domestic', values='delivery_on_time')\n",
    "trade_lane_accuracy.columns = ['International', 'Domestic']\n",
    "trade_lane_accuracy = trade_lane_accuracy.reset_index().sort_values('Domestic', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "trade_lane_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4422f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize domestic vs international accuracy by carrier\n",
    "trade_lane_long = trade_lane_accuracy.melt(id_vars='carrier_name', value_vars=['Domestic', 'International'],\n",
    "                                     var_name='Trade Lane', value_name='Accuracy')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "bar = sns.barplot(x='carrier_name', y='Accuracy', hue='Trade Lane', data=trade_lane_long)\n",
    "plt.title('EDD Accuracy by Carrier and Trade Lane Type')\n",
    "plt.xlabel('carrier_name')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Trade Lane')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6904be4",
   "metadata": {},
   "source": [
    "## Time-based Analysis\n",
    "\n",
    "Let's see if there are any temporal patterns in EDD accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d00cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "analysis_df['pickup_year'] = analysis_df['pick_up'].dt.year\n",
    "analysis_df['pickup_month'] = analysis_df['pick_up'].dt.month\n",
    "analysis_df['pickup_day'] = analysis_df['pick_up'].dt.day\n",
    "analysis_df['pickup_weekday'] = analysis_df['pick_up'].dt.dayofweek\n",
    "\n",
    "# Accuracy by month\n",
    "monthly_accuracy = analysis_df.groupby(['pickup_year', 'pickup_month'])['delivery_on_time'].mean().reset_index()\n",
    "monthly_accuracy['year_month'] = monthly_accuracy['pickup_year'].astype(str) + '-' + monthly_accuracy['pickup_month'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_accuracy['year_month'], monthly_accuracy['delivery_on_time'], marker='o')\n",
    "plt.title('EDD Accuracy Trend Over Time')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy by day of week\n",
    "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_accuracy = analysis_df.groupby('pickup_weekday')['delivery_on_time'].mean().reset_index()\n",
    "weekday_accuracy['weekday_name'] = weekday_accuracy['pickup_weekday'].apply(lambda x: weekday_names[x])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='weekday_name', y='delivery_on_time', data=weekday_accuracy, order=weekday_names)\n",
    "plt.title('EDD Accuracy by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0534b",
   "metadata": {},
   "source": [
    "## EDD Window Analysis\n",
    "\n",
    "Let's analyze the EDD window sizes and their impact on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EDD window size in days\n",
    "analysis_df['edd_window_days'] = (analysis_df['edd_end'] - analysis_df['edd_start']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Group by window size range\n",
    "def window_category(days):\n",
    "    if pd.isna(days):\n",
    "        return 'Unknown'\n",
    "    elif days < 1:\n",
    "        return '<1 day'\n",
    "    elif days < 2:\n",
    "        return '1-2 days'\n",
    "    elif days < 3:\n",
    "        return '2-3 days'\n",
    "    elif days < 5:\n",
    "        return '3-5 days'\n",
    "    else:\n",
    "        return '>5 days'\n",
    "\n",
    "analysis_df['window_category'] = analysis_df['edd_window_days'].apply(window_category)\n",
    "\n",
    "# Calculate accuracy by window size\n",
    "window_accuracy = analysis_df.groupby('window_category')['delivery_on_time'].agg(['count', 'mean']).reset_index()\n",
    "window_accuracy.columns = ['Window Size', 'Count', 'Accuracy']\n",
    "\n",
    "# Order categories properly\n",
    "window_order = ['<1 day', '1-2 days', '2-3 days', '3-5 days', '>5 days', 'Unknown']\n",
    "window_accuracy['Window Size'] = pd.Categorical(window_accuracy['Window Size'], categories=window_order, ordered=True)\n",
    "window_accuracy = window_accuracy.sort_values('Window Size')\n",
    "\n",
    "# Display results\n",
    "window_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65862845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize window size impact on accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Window Size', y='Accuracy', data=window_accuracy)\n",
    "plt.title('EDD Accuracy by Window Size')\n",
    "plt.xlabel('EDD Window Size')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841245e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average window size by carrier\n",
    "carrier_window = analysis_df.groupby('carrier_name')['edd_window_days'].mean().reset_index()\n",
    "carrier_window = carrier_window.sort_values('edd_window_days', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='carrier_name', y='edd_window_days', data=carrier_window)\n",
    "plt.title('Average EDD Window Size by Carrier')\n",
    "plt.xlabel('carrier_name')\n",
    "plt.ylabel('Average Window Size (Days)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456c2ae",
   "metadata": {},
   "source": [
    "## EDD Updates Analysis\n",
    "\n",
    "Let's analyze how often EDDs are updated and how this affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if EDD was updated (new values present)\n",
    "analysis_df['edd_updated'] = ~pd.isna(analysis_df['new_parcel_expected_time_first_start'])\n",
    "\n",
    "# Calculate accuracy for updated vs. non-updated EDDs\n",
    "update_accuracy = analysis_df.groupby('edd_updated')['delivery_on_time'].mean().reset_index()\n",
    "update_accuracy.columns = ['EDD Updated', 'Accuracy']\n",
    "\n",
    "# Display results\n",
    "update_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how carriers differ in update frequency\n",
    "carrier_updates = analysis_df.groupby('carrier_name')['edd_updated'].mean().reset_index()\n",
    "carrier_updates = carrier_updates.sort_values('edd_updated', ascending=False)\n",
    "carrier_updates.columns = ['carrier_name', 'Update Frequency']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='carrier_name', y='Update Frequency', data=carrier_updates)\n",
    "plt.title('EDD Update Frequency by Carrier')\n",
    "plt.xlabel('carrier_name')\n",
    "plt.ylabel('Proportion of EDDs Updated')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423e5e0",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "Based on our analysis of EDD accuracy across carriers, we can draw the following conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df943804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary of carrier performance\n",
    "summary_df = carrier_accuracy.rename(columns={'accuracy_rate': 'edd_accuracy'})\n",
    "\n",
    "# Add average days early/late\n",
    "avg_days = analysis_df.groupby('carrier_name')['days_early_late'].mean().reset_index()\n",
    "summary_df = summary_df.merge(avg_days, on='carrier_name')\n",
    "\n",
    "# Add EDD window size\n",
    "summary_df = summary_df.merge(carrier_window, on='carrier_name')\n",
    "\n",
    "# Add update frequency\n",
    "summary_df = summary_df.merge(carrier_updates.rename(columns={'carrier_name': 'carrier_name'}), on='carrier_name')\n",
    "\n",
    "# Calculate percent of very late deliveries\n",
    "very_late = analysis_df[analysis_df['delivery_category'] == 'Very Late (>1 day)'].groupby('carrier_name').size() / \\\n",
    "            analysis_df.groupby('carrier_name').size()\n",
    "very_late = very_late.reset_index().rename(columns={0: 'pct_very_late'})\n",
    "summary_df = summary_df.merge(very_late, on='carrier_name')\n",
    "\n",
    "# Order by accuracy\n",
    "summary_df = summary_df.sort_values('edd_accuracy', ascending=False)\n",
    "\n",
    "# Display comprehensive summary\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166569c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the key metrics in a radar chart for top carriers\n",
    "# Select the top 5 carriers by volume\n",
    "top_carriers = summary_df.sort_values('total_deliveries', ascending=False).head(5)['carrier_name'].tolist()\n",
    "top_carrier_data = summary_df[summary_df['carrier_name'].isin(top_carriers)]\n",
    "\n",
    "# Normalize the metrics for radar chart\n",
    "metrics = ['edd_accuracy', 'Update Frequency']\n",
    "# For days_early_late, we want to invert it so negative values (early) are better\n",
    "top_carrier_data['days_early_late_norm'] = -top_carrier_data['days_early_late']\n",
    "# For window days, smaller is generally better\n",
    "top_carrier_data['window_days_inv'] = 1/top_carrier_data['edd_window_days']\n",
    "\n",
    "# Add these normalized metrics\n",
    "metrics.extend(['days_early_late_norm', 'window_days_inv'])\n",
    "\n",
    "# If using Plotly, we can create a radar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, carrier in enumerate(top_carrier_data['carrier_name']):\n",
    "    values = top_carrier_data.loc[top_carrier_data['carrier_name'] == carrier, metrics].values.flatten().tolist()\n",
    "    # Close the loop for the radar\n",
    "    values.append(values[0])\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=metrics + [metrics[0]],\n",
    "        fill='toself',\n",
    "        name=carrier\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1]\n",
    "        )),\n",
    "    showlegend=True,\n",
    "    title=\"Carrier Performance Comparison\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420be73",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **Carrier Accuracy Ranking**: Based on our analysis, we can clearly identify which carriers have the highest EDD accuracy rates.\n",
    "\n",
    "2. **Domestic vs. International**: There's a notable difference in EDD accuracy between domestic and international shipments, with domestic shipments generally having higher accuracy.\n",
    "\n",
    "3. **EDD Window Size Impact**: Carriers with larger EDD windows tend to have higher accuracy rates, but this comes at the expense of precision for customers.\n",
    "\n",
    "4. **Update Patterns**: Carriers that update their EDDs more frequently tend to have better accuracy, suggesting that active monitoring and adjustment leads to better predictions.\n",
    "\n",
    "5. **Timing Patterns**: There are clear patterns in delivery timing, with some carriers consistently delivering early while others tend to deliver late.\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "Based on our findings, we recommend:\n",
    "\n",
    "1. Work with lower-performing carriers to improve their EDD accuracy by implementing more frequent updates and better predictive models.\n",
    "\n",
    "2. Consider adjusting EDD window sizes based on trade lane and carrier performance to balance accuracy with customer expectations.\n",
    "\n",
    "3. Investigate carriers with high rates of very late deliveries to identify root causes and potential improvements.\n",
    "\n",
    "4. Leverage the patterns identified in day-of-week and seasonal trends to better manage customer expectations during peak periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ec3ba",
   "metadata": {},
   "source": [
    "## Approach for Handling EDD Parameters\n",
    "\n",
    "The dataset contains multiple parameters related to Estimated Delivery Dates (EDD):\n",
    "\n",
    "* **old_parcel_expected_time_first_start / old_parcel_expected_time_latest_start**: The start time of the initial EDD received from the carrier.\n",
    "* **old_parcel_expected_time_first_end / old_parcel_expected_time_latest_end**: The end time of the initial EDD received from the carrier.\n",
    "* **new_parcel_expected_time_first_start / new_parcel_expected_time_latest_start**: The NEW start time of the updated EDD received from the carrier.\n",
    "* **new_parcel_expected_time_first_end / new_parcel_expected_time_latest_end**: The NEW end time of the updated EDD received from the carrier.\n",
    "\n",
    "### Our Approach\n",
    "\n",
    "For this analysis, I've decided to adopt the following strategy for handling EDD parameters:\n",
    "\n",
    "1. **Prioritize New Values**: Use the newest available EDD values when present, as they represent the carrier's most recent prediction and should theoretically be more accurate due to being based on the most up-to-date information.\n",
    "\n",
    "2. **Fall Back to Original Values**: When new values aren't available, fall back to the original EDD values.\n",
    "\n",
    "3. **Use First Start and Latest End**: For defining the EDD window, use the earliest start time and the latest end time to capture the full possible delivery window the carrier has committed to.\n",
    "\n",
    "4. **Consider Updates as a Feature**: Track whether EDDs were updated as a separate feature for analysis, as this may correlate with accuracy and carrier performance.\n",
    "\n",
    "This approach allows us to:\n",
    "- Always use the most current information available\n",
    "- Maintain the full promised delivery window for fairness in accuracy assessment\n",
    "- Analyze the impact of EDD updates on delivery accuracy\n",
    "- Better understand carrier forecasting capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the EDD columns in the data\n",
    "edd_columns = [col for col in parcel_df.columns if 'expected_time' in col]\n",
    "print(\"EDD-related columns in the dataset:\")\n",
    "for col in edd_columns:\n",
    "    missing = parcel_df[col].isna().sum()\n",
    "    missing_pct = (missing / len(parcel_df) * 100).round(2)\n",
    "    print(f\"- {col}: {missing} missing values ({missing_pct}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle EDD parameters more comprehensively\n",
    "def handle_edd_parameters(df):\n",
    "    \"\"\"Process EDD parameters according to our defined approach\"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Check if the new EDD values are actually different from the old ones when both exist\n",
    "    if ('new_parcel_expected_time_first_start' in df.columns and \n",
    "        'old_parcel_expected_time_first_start' in df.columns):\n",
    "        \n",
    "        # For rows where both new and old values exist, check if they're different\n",
    "        mask = (~df['new_parcel_expected_time_first_start'].isna() & \n",
    "                ~df['old_parcel_expected_time_first_start'].isna())\n",
    "        \n",
    "        if mask.sum() > 0:\n",
    "            # Calculate the average difference between new and old start times (in hours)\n",
    "            time_diff = (df.loc[mask, 'new_parcel_expected_time_first_start'] - \n",
    "                         df.loc[mask, 'old_parcel_expected_time_first_start']).dt.total_seconds() / 3600\n",
    "            \n",
    "            print(f\"Average change in EDD start time: {time_diff.mean():.2f} hours\")\n",
    "            print(f\"Median change in EDD start time: {time_diff.median():.2f} hours\")\n",
    "            \n",
    "            # Check the direction of changes (earlier or later)\n",
    "            earlier = (time_diff < 0).sum()\n",
    "            later = (time_diff > 0).sum()\n",
    "            unchanged = (time_diff == 0).sum()\n",
    "            \n",
    "            print(f\"EDD updates: {earlier} earlier, {later} later, {unchanged} unchanged\")\n",
    "    \n",
    "    # 1. Use new values when available, fall back to old values\n",
    "    df_processed['edd_start'] = df_processed['new_parcel_expected_time_first_start'].fillna(\n",
    "        df_processed['old_parcel_expected_time_first_start'])\n",
    "        \n",
    "    df_processed['edd_end'] = df_processed['new_parcel_expected_time_latest_end'].fillna(\n",
    "        df_processed['old_parcel_expected_time_latest_end'])\n",
    "    \n",
    "    # 2. Track if the EDD was updated\n",
    "    df_processed['edd_updated'] = ~df_processed['new_parcel_expected_time_first_start'].isna()\n",
    "    \n",
    "    # 3. Calculate the EDD window size in days\n",
    "    df_processed['edd_window_days'] = (\n",
    "        df_processed['edd_end'] - df_processed['edd_start']).dt.total_seconds() / (24 * 3600)\n",
    "    \n",
    "    # 4. Flag potentially problematic EDDs (e.g., end before start)\n",
    "    if 'edd_start' in df_processed.columns and 'edd_end' in df_processed.columns:\n",
    "        invalid_edd = df_processed['edd_end'] < df_processed['edd_start']\n",
    "        if invalid_edd.sum() > 0:\n",
    "            print(f\"Found {invalid_edd.sum()} rows where EDD end is before EDD start\")\n",
    "            df_processed['invalid_edd'] = invalid_edd\n",
    "    \n",
    "    # 5. Categorize EDD window size\n",
    "    def window_category(days):\n",
    "        if pd.isna(days):\n",
    "            return 'Unknown'\n",
    "        elif days < 0:\n",
    "            return 'Invalid (negative)' \n",
    "        elif days < 1:\n",
    "            return '<1 day'\n",
    "        elif days < 2:\n",
    "            return '1-2 days'\n",
    "        elif days < 3:\n",
    "            return '2-3 days'\n",
    "        elif days < 5:\n",
    "            return '3-5 days'\n",
    "        else:\n",
    "            return '>5 days'\n",
    "            \n",
    "    df_processed['edd_window_category'] = df_processed['edd_window_days'].apply(window_category)\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the EDD parameter handling function\n",
    "parcel_df = handle_edd_parameters(parcel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze EDD updates by carrier\n",
    "if 'edd_updated' in parcel_df.columns:\n",
    "    # Percentage of shipments with updated EDDs by carrier\n",
    "    carrier_updates = parcel_df.groupby('carrier_name')['edd_updated'].mean().reset_index()\n",
    "    carrier_updates.columns = ['carrier_name', 'Update Frequency']\n",
    "    carrier_updates = carrier_updates.sort_values('Update Frequency', ascending=False)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Percentage of shipments with updated EDDs by carrier:\")\n",
    "    carrier_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy between updated and non-updated EDDs\n",
    "if 'edd_updated' in parcel_df.columns and 'delivery_on_time' in parcel_df.columns:\n",
    "    update_accuracy = parcel_df.groupby('edd_updated')['delivery_on_time'].agg(['count', 'mean']).reset_index()\n",
    "    update_accuracy.columns = ['EDD Updated', 'Shipment Count', 'Accuracy Rate']\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nAccuracy comparison between updated and non-updated EDDs:\")\n",
    "    update_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bfd6b",
   "metadata": {},
   "source": [
    "### EDD Update Impact Visualization\n",
    "\n",
    "Let's visualize how EDD updates affect accuracy by carrier. This will help us understand which carriers benefit most from updating their EDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy for updated vs. non-updated EDDs by carrier\n",
    "if 'edd_updated' in parcel_df.columns and 'delivery_on_time' in parcel_df.columns:\n",
    "    carrier_update_impact = parcel_df.groupby(['carrier_name', 'edd_updated'])['delivery_on_time'].mean().reset_index()\n",
    "    carrier_update_impact = carrier_update_impact.pivot(index='carrier_name', columns='edd_updated', values='delivery_on_time')\n",
    "    carrier_update_impact.columns = ['Without Update', 'With Update']\n",
    "    carrier_update_impact['Impact'] = carrier_update_impact['With Update'] - carrier_update_impact['Without Update']\n",
    "    carrier_update_impact = carrier_update_impact.sort_values('Impact', ascending=False).reset_index()\n",
    "    \n",
    "    # Create a visualization of the impact\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    ax = sns.barplot(x='carrier_name', y='Impact', data=carrier_update_impact)\n",
    "    \n",
    "    # Add a horizontal line at zero to show positive vs negative impact\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Color bars based on positive or negative impact\n",
    "    for i, imp in enumerate(carrier_update_impact['Impact']):\n",
    "        if imp > 0:\n",
    "            ax.patches[i].set_facecolor('green')\n",
    "        else:\n",
    "            ax.patches[i].set_facecolor('red')\n",
    "    \n",
    "    plt.title('Impact of EDD Updates on Delivery Accuracy by Carrier')\n",
    "    plt.xlabel('carrier_name')\n",
    "    plt.ylabel('Change in Accuracy (percentage points)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display the numerical results as well\n",
    "    carrier_update_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44307a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if handle_missing_values still needs to be called\n",
    "# It's redundant with our new handle_edd_parameters function for EDD fields, but we still need it for other fields\n",
    "parcel_df_cleaned = handle_missing_values(parcel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ecef80",
   "metadata": {},
   "source": [
    "## Final Recommendations Based on EDD Analysis\n",
    "\n",
    "Based on our analysis of EDD parameters and their impact on delivery accuracy:\n",
    "\n",
    "1. **EDD Update Strategy**: We recommend implementing a regular EDD update process for all carriers, as our analysis shows that updated EDDs tend to be more accurate for most carriers.\n",
    "\n",
    "2. **Carrier-Specific Approaches**: \n",
    "   - For carriers showing negative impact from updates, investigate why their updated predictions are less accurate\n",
    "   - For carriers with high accuracy but low update frequency, consider whether more frequent updates would further improve performance\n",
    "\n",
    "3. **Optimal EDD Window Size**: Balance accuracy with precision by targeting EDD windows that are:\n",
    "   - Large enough to maintain high on-time delivery rates\n",
    "   - Small enough to provide valuable information to recipients\n",
    "\n",
    "4. **Data Quality Improvements**: Implement validation rules for EDDs to prevent invalid timeframes (end before start) and ensure consistent application of updates across all shipments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
